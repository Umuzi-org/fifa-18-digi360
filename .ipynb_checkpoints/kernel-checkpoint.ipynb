{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.ipynb_checkpoints', 'CompleteDataset.csv', 'kernel.ipynb', 'README.md']\n"
     ]
    }
   ],
   "source": [
    "# (c) Sydney Sedibe, 2018\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Seaborn for pairplots\n",
    "\n",
    "# Set text size\n",
    "plt.rcParams['font.size'] = 18\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "file_list = os.listdir(\"./\")\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "848b2bb90fc7be36fd32aeac06a41aa15b67d8fd"
   },
   "source": [
    "**This dataset contains information about Players from the EA Sports game, FIFA 18. We will take this data, clean it, analyse it, and gain insights from it. First let's load the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "339dd3ae4e9a14c09ad16dbbc94d0c4cd9ac6064",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../input/.ipynb_checkpoints' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-28e1db576896>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0modf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# odf = original dataframe with complete dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0modf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1050\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'../input/.ipynb_checkpoints' does not exist"
     ]
    }
   ],
   "source": [
    "odf = pd.read_csv(\"CompleteDataset.csv\") # odf = original dataframe with complete dataset\n",
    "odf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d7032805b61d6db60341726485c52a808db44ec2"
   },
   "source": [
    "**Now, let's inspect it...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5c20fec9f07f48edf7c217aac2775a2663cc9189"
   },
   "outputs": [],
   "source": [
    "def showDetails(df):\n",
    "    print(\"-------------------------------------------------------------------------------------------------------------------\")\n",
    "    print('{:>35}'.format(\"Shape of dataframe:\") + '{:>12}'.format(str(df.shape)))\n",
    "    containsNulls = \"Yes\" if df.isnull().any().any() else \"No\"\n",
    "    print(\"Does dataframe contain null values: \" + containsNulls)\n",
    "    null_columns = df.columns[df.isnull().any()]\n",
    "    print(\"Number of columns with null values: \" + str(df[null_columns].isnull().any().sum()))\n",
    "    null_rows = df[df.isnull().any(axis=1)][null_columns]\n",
    "    print(\"Number of records with null values: \" + str(len(null_rows)))\n",
    "    print('{:>35}'.format(\"Percentage of null records:\") + '{:>6.2f}'.format(len(null_rows) / len(df) * 100) + \"%\")\n",
    "    print(\"-------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "showDetails(odf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "825219ca84434dc7d16b4d99f9ac564895a01de4"
   },
   "source": [
    "**Our dataframe contains 17 981 records, with 75 columns. There are 27 columns and 2 235 records with null values, and these null records account for 12.43% of the total number of records .**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9cb83f5b5db26467f281c4a637ec1bee386404be"
   },
   "source": [
    "**Let's inspect these null records to see if we can find the source of the missing data...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "67c7c513f95bfbd2c17a368d4e2c3a532fa116de"
   },
   "outputs": [],
   "source": [
    "nv_df = odf[odf.isnull().any(axis=1)] # nv_df ==> null value dataframe\n",
    "showDetails(nv_df)\n",
    "nv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c62bcfd6889a67a22be21a2938318951b62dbdae"
   },
   "source": [
    "**A quick inspection of the null value records in our dataframe show that those null value records are for goalkeepers, mostly. This is because goalkeepers are not assigned an overall for playing other positions on the field.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f71e77a2e324cdb765ce7779204a2e58e3869090"
   },
   "source": [
    "**We are now going to create a new working dataframe with columns that are relevent to our purposes of applying simple regression on the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ff3b8cd67c0d42d45b7471638243a703a9b004c6"
   },
   "outputs": [],
   "source": [
    "wdf = odf[['Overall', 'Value', 'Wage', 'Aggression', 'Free kick accuracy', 'Sprint speed', 'Finishing']]\n",
    "showDetails(wdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "031f1084bc0a0a7560ed63bb50489f064c9b31ab"
   },
   "source": [
    "**It turns out by choosing these columns, we dropped all the null-values from the dataframe. So now we still have 17 981 records, just with 7 columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ea3353744509d9147cab10c66b9fb0cab53ef521"
   },
   "outputs": [],
   "source": [
    "wdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f956365c23a28780bf1efecd6d039e9bdbd574b1"
   },
   "source": [
    "**In order to apply regression with the columns \"Value\" and \"Wage\", we have to convert their string values to numeric types. Here's a function to clean those two columns that...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b8179a20e365894cec6e57eac9158cf4ba3281fb"
   },
   "outputs": [],
   "source": [
    "def toFloat(string):\n",
    "    \"\"\"Function to convert Wage and Value strings to floats\"\"\"\n",
    "    string = string.strip(\" \")\n",
    "    if string[-1] == 'M':\n",
    "        return float(string[1:-1]) * 1000000\n",
    "    elif string[-1] == 'K':\n",
    "        return float(string[1:-1]) * 1000\n",
    "    else:\n",
    "        return float(string[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3c636730984c5831bf9a548065e361ff56d8d3e4"
   },
   "outputs": [],
   "source": [
    "wdf['Value'] = [toFloat(value) for value in wdf['Value']]\n",
    "wdf['Wage'] = [toFloat(wage) for wage in wdf['Wage']]\n",
    "wdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b66221277f834095604258f4a34a4172614b6396"
   },
   "source": [
    "The \"Wage\" and \"Value\" columns are now numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a7b8998d1b7038789f33a7d14d2669425c3cbbef"
   },
   "outputs": [],
   "source": [
    "print(\"There are \" + str(len(wdf[wdf[\"Wage\"] == 0])) + \" rows with a wage value of 0 in the Wage column\")\n",
    "print(\"There are \" + str(len(wdf[wdf[\"Value\"] == 0])) + \" rows with a player-value of 0 in the Value column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7c9e0b9e041adb3070821b95cb0e50342a0c544d"
   },
   "source": [
    "Let's replace all the 0-values in the \"Wage\" and \"Value\" columns with the non-zero mean..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b726ae4536e6234945f50790a1593368c188f90"
   },
   "outputs": [],
   "source": [
    "def replaceZeroValues(df, column):\n",
    "    subset = df[ df[column] != 0 ][column]\n",
    "    nonzero_mean = subset.mean()\n",
    "    print(\"The nonzero_mean for \" + column + \" is \" + str(nonzero_mean))\n",
    "    df.loc[ df[column] == 0, column ] = nonzero_mean\n",
    "    \n",
    "replaceZeroValues(wdf, \"Wage\")\n",
    "replaceZeroValues(wdf, \"Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5f989a0bc0a6c77f2ef3b165d5e68666927313cd"
   },
   "outputs": [],
   "source": [
    "print(\"There are \" + str(len(wdf[wdf[\"Wage\"] == 0])) + \" rows with a wage value of 0 in the Wage column\")\n",
    "print(\"There mininum value for the Wage column is \" + str(wdf[\"Wage\"].min()))\n",
    "print(\"There are \" + str(len(wdf[wdf[\"Value\"] == 0])) + \" rows with a player-value of 0 in the Value column\")\n",
    "print(\"There mininum value for the Value column is \" + str(wdf[\"Value\"].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0759424d570e7df99383ee8b033d287c71def236"
   },
   "outputs": [],
   "source": [
    "wdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "34ddb88fef331db079158566648b4927757c6377"
   },
   "source": [
    "Now the \"Value\" and \"Wage' columns are now floats, so we can run a regression on them. Let's now clean up the \"non-null object\" columns that need to be numeric (float or int)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9918a886b102ba3b06dc8bbda50b64ad528a2a4a"
   },
   "outputs": [],
   "source": [
    "def removeExtraChars(string):\n",
    "    sc = \"\" #special character: either '+' or '-'\n",
    "    if \"+\" in string:\n",
    "        sc = \"+\"\n",
    "    elif \"-\" in string:\n",
    "        sc = \"-\"\n",
    "    else:\n",
    "        return int(string)\n",
    "    return int(string[:string.find(sc)])\n",
    "\n",
    "def cleanUpColumn(df, column):\n",
    "    return [removeExtraChars(row) for row in df[column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2610c7e45ee4e59ce899344f8f12a869c411cced"
   },
   "outputs": [],
   "source": [
    "wdf[\"Aggression\"] = cleanUpColumn(wdf, \"Aggression\")\n",
    "wdf[\"Free kick accuracy\"] = cleanUpColumn(wdf, \"Free kick accuracy\")\n",
    "wdf[\"Sprint speed\"] = cleanUpColumn(wdf, \"Sprint speed\")\n",
    "wdf[\"Finishing\"] = cleanUpColumn(wdf, \"Finishing\")\n",
    "\n",
    "wdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ffde6d5baa55c59111031b859123b041bddc77c2"
   },
   "source": [
    "Now we finally have all the columns cleaned up and numeric. Let's pair-plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "64fb84add73f64eb2a0cf2f3c2f88460a3b6678c"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(wdf);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
